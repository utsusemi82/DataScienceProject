## Telecom Churn Prediction

**Churn prediction** is a critical challenge in the *telecom* industry. Accurately identifying customers likely to leave can help companies implement retention strategies. 

In this project, I will use a real-world telecom dataset to build a Machine Learning model that predicts customer churn and deploy a simple Streamlit app and create DV dashboard using PowerBI/Tableau if possible.

---
Telecom Churn Dataset:
- https://www.kaggle.com/datasets/mnassrib/telecom-churn-datasets
- https://www.kaggle.com/code/kashnitsky/topic-2-visual-data-analysis-in-python (Data Visualization & Analysis)
---
Overview:
1. Introduction
2. Load & Understand the Data
3. Data Preprocessing
4. Exploratory Data Analysis (EDA)
5. Feature Engineering
6. Model Building (Random Forest) & Evaluation
7. Model Comparison (ROC Curve)
8. Summary + Model Evaluation (Accuracy, Precision, Recall, F1, AUC..)
9. Streamlit Deployment + Data Visualisation (Storytelling)

----
I will try a lot of *ML supervised classification techniques* for learning and testing purposes for my revision:

| **Algorithm**                 | **Description**                                                                                              |
|------------------------------|--------------------------------------------------------------------------------------------------------------|
| **Random Forest**            | An ensemble learning method that builds multiple decision trees and merges their results for more accurate and stable predictions. |
| **Logistic Regression**      | A statistical technique used for binary classification that estimates the probability of a class label.     |
| **Support Vector Machine (SVM)** | A supervised learning algorithm that finds the optimal hyperplane to separate classes in a high-dimensional space. |
| **K-Nearest Neighbors (KNN)**| A non-parametric algorithm that classifies data points based on the majority label among their nearest neighbors. |
| **Neural Networks**          | A set of algorithms inspired by the human brain that recognize complex patterns through layers of interconnected nodes. |
| **Decision Trees**           | A tree-like model used for decision making, where each node represents a feature and each leaf a class label. |
| **Gradient Boosting**        | An ensemble technique that sequentially builds weak learners (typically decision trees) to correct the errors of previous models. |
| **XGBoost**                  | An efficient and scalable implementation of gradient boosting that excels in speed and performance for structured data tasks. |


