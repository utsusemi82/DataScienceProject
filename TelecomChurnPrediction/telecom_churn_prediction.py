# -*- coding: utf-8 -*-
"""Telecom Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/111W856t_hhx9Ee1HYgXNNOz4ggrwMY3S

# **Telecom Churn Prediction**

**Churn prediction** is a critical challenge in the telecom industry. Accurately identifying customers likely to leave can help companies implement retention strategies.

In this project, I use a real-world telecom dataset to build a ML model that predicts customer churn. I will also explain the model using SHAP and deploy a simple Streamlit app.
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("mnassrib/telecom-churn-datasets")

print("Path to dataset files:", path)

!python --version

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import joblib
from google.colab import files

"""#### Load & Understand Data

Load both training and testing dataset.
*   churn-bigml-80.csv → training data
*   churn-bigml-20.csv → test data
"""

train = pd.read_csv(f"{path}/churn-bigml-80.csv")
test = pd.read_csv(f"{path}/churn-bigml-20.csv")

train.head()

train.info()

train.describe()

# Check for missing values
train.isnull().sum()

train.columns

"""#### Data Preprocessing"""

# Convert 'yes'/'no' to 1/0 for categorical features
train = train.replace({'yes': 1, 'no': 0})

# One-hot encode categorical variables (if there are any left)
train = pd.get_dummies(train, drop_first=True)

# Preview the data after encoding
train.head()

"""#### Exploratory Data Analysis (EDA)"""

sns.set(style="whitegrid")

# Churn Distribution
plt.figure(figsize=(8, 6))
sns.countplot(x='Churn', data=train, palette='pastel')
plt.title('Churn Distribution')
plt.xlabel('Churn')
plt.ylabel('Count')
plt.show()

# International Plan vs Churn
plt.figure(figsize=(8, 6))
sns.countplot(x='International plan_Yes', hue='Churn', data=train)
plt.title('International Plan vs Churn')
plt.xlabel('Churn')
plt.ylabel('Count')
plt.show()

# Customer Service Calls vs Churn
plt.figure(figsize=(12, 6))
sns.countplot(x='Customer service calls', hue='Churn',edgecolor='black', data=train)
plt.xlabel('Customer Service Calls')
plt.ylabel('Count')
plt.title('Customer Service Calls vs Churn')
plt.show()

# Call Minutes Distribution by Churn
plt.figure(figsize=(12, 6))
sns.histplot(data=train, x='Total day minutes', hue='Churn', kde=True)
plt.title('Call Minutes Distribution by Churn')
plt.xlabel('Total day minutes')
plt.show()

# Drop non-numerical variables
numerical = list(
    set(train.columns)
    - {
        "State",
        "International plan",
        "Voice mail plan",
        "Area code",
        "Churn",
        "Customer service calls",
    }
)

# Calculate and plot
corr_matrix = train[numerical].corr()
sns.heatmap(corr_matrix);

"""#### Feature Engineering"""

from sklearn.model_selection import train_test_split

X = train.drop('Churn', axis=1)
y = train['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

"""#### Model Building

-  Random Forest Classifier(default)
- Logistic Regression
- KNeighbors Classifier
- SVM Classifier
- Decision Tree Classifier
- Gradient Boost Classifier
- Lightweight Neural Network

*Note: trying others just for training purpose*
"""

# Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

print("Random Forest Classifier (Default):")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

logistic_model = LogisticRegression(max_iter=5000)
logistic_model.fit(X_train, y_train)

y_pred = logistic_model.predict(X_test)

print("Logistic Regression Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

#KNN Model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import numpy as np

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create KNN model with adjusted number of neighbours
# Increase neighbours and weighted voting)
knn = KNeighborsClassifier(n_neighbors=20, weights='distance')
knn.fit(X_train_scaled, y_train)

y_pred = knn.predict(X_test_scaled)

print("Adjusted K-Nearest Neighbors Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Optional: Evaluate using cross-validation
cv_scores = cross_val_score(knn, X_train_scaled, y_train, cv=5)
print("Average cross-validation score:", np.mean(cv_scores))

# SVM
from sklearn.svm import LinearSVC

svm = LinearSVC()
svm.fit(X_train_scaled, y_train)

y_pred = svm.predict(X_test_scaled)

print("Support Vector Machine Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Decision Tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

y_pred = dt.predict(X_test)

print("Decision Tree Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)

y_pred = gb.predict(X_test)

print("Gradient Boosting Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Lightweight Neural Network
# Assuming a small network with one hidden layer of 100 neurons
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report

neural_network = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
neural_network.fit(X_train, y_train)

y_pred = neural_network.predict(X_test)

print("Lightweight Neural Network Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""### Model Comparison & Evaluation

#### ROC Curve
"""

from xgboost import XGBClassifier

models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "GradientBoosting": GradientBoostingClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

for name, clf in models.items():
    clf.fit(X_train, y_train)
    preds = clf.predict(X_test)
    acc = accuracy_score(y_test, preds)
    print(f"{name} Accuracy: {acc:.4f}")

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer

plt.figure(figsize=(10, 7))

for name, clf in models.items():
    # Get predicted probabilities
    if hasattr(clf, "predict_proba"):
        y_proba = clf.predict_proba(X_test)[:, 1]
    else:
        y_proba = clf.decision_function(X_test)

    # Compute ROC curve and AUC
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    # Plot
    plt.plot(fpr, tpr, lw=2, label=f"{name} (AUC = {roc_auc:.2f})")

# Plot random line
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from itertools import cycle

# Assuming y_test is not binarized yet
y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))
n_classes = y_test_binarized.shape[1]

# Function to plot ROC curve for each class
def plot_multiclass_roc_auc(model, X_test, y_test_binarized, n_classes, model_name):
    # Binarize the output
    y_score = model.predict_proba(X_test)

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Aggregate all false positive rates
    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

    # Interpolate all ROC curves at these points
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

    # Average and compute AUC
    mean_tpr /= n_classes

    # Plot all ROC curves
    plt.figure()
    colors = cycle(['blue', 'red', 'green', 'yellow', 'purple', 'orange'])
    for i, color in zip(range(n_classes), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2,
                 label='ROC curve of class {0} (area = {1:0.2f})'
                 ''.format(i, roc_auc[i]))

    plt.plot([0, 1], [0, 1], 'k--', lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Receiver Operating Characteristic for {model_name}')
    plt.legend(loc="lower right")
    plt.show()

# Plot ROC AUC for each model
plot_multiclass_roc_auc(rf_model, X_test, y_test_binarized, n_classes, 'Random Forest')
plot_multiclass_roc_auc(logistic_model, X_test, y_test_binarized, n_classes, 'Logistic Regression')
plot_multiclass_roc_auc(knn, X_test_scaled, y_test_binarized, n_classes, 'K-Nearest Neighbors')
#plot_multiclass_roc_auc(svm, X_test, y_test_binarized, n_classes, 'Support Vector Machine')
plot_multiclass_roc_auc(gb, X_test, y_test_binarized, n_classes, 'Gradient Boost')
plot_multiclass_roc_auc(dt, X_test, y_test_binarized, n_classes, 'Decision Tree')
plot_multiclass_roc_auc(neural_network, X_test, y_test_binarized, n_classes, 'Neural Network')

"""### Summary"""

from sklearn.metrics import precision_score, recall_score, f1_score

# Collect results into a summary DataFrame
results = []

for name, clf in models.items():
    y_pred = clf.predict(X_test)
    y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, "predict_proba") else clf.decision_function(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    results.append({
        'Model': name,
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1 Score': f1,
        'ROC AUC': roc_auc
    })

results_df = pd.DataFrame(results).sort_values(by='ROC AUC', ascending=False)
results_df.reset_index(drop=True, inplace=True)
results_df.style.background_gradient(cmap='Blues')

"""####  Precision-Recall Curve Comparison"""

from sklearn.metrics import precision_recall_curve

plt.figure(figsize=(10, 7))

for name, clf in models.items():
    y_scores = clf.predict_proba(X_test)[:, 1] if hasattr(clf, "predict_proba") else clf.decision_function(X_test)
    precision, recall, _ = precision_recall_curve(y_test, y_scores)
    plt.plot(recall, precision, lw=2, label=f"{name}")

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve Comparison')
plt.legend(loc='best')
plt.grid(True)
plt.show()

"""### Streamlit Deployment

- final trained model: Random Forest Model
"""

# Save Model

model = joblib.dump(rf_model, 'rf.joblib')[0]
files.download(model)

# Streamlit app (app.py)
!pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import joblib

# Load the trained model
model = joblib.load('rf.joblib')

import streamlit as st
import pandas as pd
import numpy as np
import joblib

# Load model
model = joblib.load("rf.joblib")

st.set_page_config(page_title="Telecom Churn Predictor", layout="centered")
st.title("📞 Telecom Customer Churn Predictor")

st.markdown("Input customer data below to predict churn probability.")

# Input features
state = st.text_input("State (2-letter code)", "KS")
account_length = st.slider("Account Length", 1, 250, 100)
area_code = st.selectbox("Area Code", [408, 415, 510])
intl_plan = st.selectbox("International Plan", ["No", "Yes"])
vmail_plan = st.selectbox("Voice Mail Plan", ["No", "Yes"])
vmail_messages = st.slider("Number of Voice Mail Messages", 0, 50, 0)
day_mins = st.slider("Total Day Minutes", 0.0, 400.0, 180.0)
day_calls = st.slider("Total Day Calls", 0, 200, 100)
day_charge = st.slider("Total Day Charge", 0.0, 60.0, 30.0)
cust_serv_calls = st.slider("Customer Service Calls", 0, 10, 1)

# One-hot encode inputs similar to training
input_dict = {
    "Account length": account_length,
    "Area code": area_code,
    "Number vmail messages": vmail_messages,
    "Total day minutes": day_mins,
    "Total day calls": day_calls,
    "Total day charge": day_charge,
    "Customer service calls": cust_serv_calls,
    "International plan_Yes": 1 if intl_plan == "Yes" else 0,
    "Voice mail plan_Yes": 1 if vmail_plan == "Yes" else 0,
}

# Convert to dataframe and ensure all expected columns exist
input_df = pd.DataFrame([input_dict])

# Predict
if st.button("Predict Churn"):
    prediction = model.predict(input_df)[0]
    proba = model.predict_proba(input_df)[0][1]

    st.subheader("Prediction Result")
    if prediction:
        st.error(f"🚨 This customer is likely to churn. (Probability: {proba:.2f})")
    else:
        st.success(f"✅ This customer is likely to stay. (Probability: {proba:.2f})")

"""#### This project successfully built a churn prediction model using Random Forest. It demonstrates the full ML lifecycle and is ideal for showcasing to recruiters and potential employers.

"""
